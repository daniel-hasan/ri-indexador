{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta pr√°tica voc√™ ir√° implementar o indexador para, logo ap√≥s, indexar o conte√∫do da Wikip√©dia. Fizemos uma implementa√ß√£o inicial na qual o √≠ndice √© composto pela classe abstrata `Index` que armazena a estrutura do √≠ndice e possui as opera√ß√µes b√°sicas do mesmo. \n",
    "\n",
    "Iremos fazer duas implementa√ß√µes desse √≠ndice: o `HashIndex` que ser√° um √≠ndice simples em mem√≥ria principal e o `FileIndex` em que as ocorr√™ncias ficar√£o em mem√≥ria secund√°ria para possibilitar a indexa√ß√£o de uma quantidade maior de p√°ginas. Assim, teremos os seguintes arquivos:\n",
    "\n",
    "- `structure.py`: Possui toda a estrutura do √≠ndice;\n",
    "- `index_structure_test.py`: Testa a estrutura do √≠ndice;\n",
    "- `file_index_test.py`: Possui os testes unit√°rios espec√≠ficos para a indexa√ß√£o das ocorrencias em arquivos da classe `FileIndex`;\n",
    "- `performance_test.py`: Executa um teste de performance (tempo de execu√ß√£o e mem√≥ria utilizada) do √≠ndice;\n",
    "- `indexer.py`: Possui as classes para o preprocessamento e prepara√ß√£o para a indexa√ß√£o;\n",
    "- `indexer_test.py`: Realiza o [teste de integra√ß√£o](https://en.wikipedia.org/wiki/Integration_testing) da pr√°tica como um todo (inclusive as fun√ß√µes da indexer.py).\n",
    "\n",
    "**Na entrega, n√£o esque√ßa de apresentar a sa√≠da de execu√ß√£o de cada atividade desta tarefa.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementa√ß√£o da classe Abstrata `Index` e classe `HashIndex`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe `Index` √© abstrata e possui os m√©todos para manipula√ß√£o do indices al√©m da estrutura do √≠ndice que √© comum em todas as estruturas que ficar√° sempre em mem√≥ria principal durante sua execu√ß√£o:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `dic_index`:  dicion√°rio em que a chave √© o termo indexa√ß√£o (string, gerenciado por esta classe) e, os valores,  podem der de diferentes tipos - dependendo da subclasse;\n",
    "- `set_documents`: conjunto de ids de documentos existentes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teremos duas subclasses a `HashIndex` e a `FileIndex` que ser√£o respons√°veis pela implementa√ß√£o dos m√©todos e cria√ß√£o da estrutura - manipulando o valor do atributo `dic_index`. Os m√©todos e as demais classes deste arquivo ser√£o discutidos ao longo das atividades. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 1 - m√©todo index da classe Index**: Este m√©todo est√° quase todo pronto e √© repons√°vel por indexar um termo com sua frequencia e documento no √≠ndice, de acordo com uma de suas subclasses. Nesse m√©todo voc√™ dever√° inicializar a vari√°vel `int_term_id` apropriadamente - substituindo os `None` correspondente: \n",
    "\n",
    "- **Caso o termo n√£o exista no √≠ndice**, dever√° obter o pr√≥ximo term_id. Esse id pode ser sequencial - verificando o tamanho do vocabul√°rio por meio do atributo `dict_index`. \n",
    "- **Caso esse termo seja encontrado**, a classe Index dever√° chamar o m√©todo `get_term_id` (m√©todo abstrato da classe `Index` implementado pelas subclasses) para obt√™-lo pois, dependendo da implementa√ß√£o, haver√° uma forma diferente de obten√ß√£o. \n",
    "\n",
    "Logo ap√≥s, voc√™ dever√° atualizar o atributo `set_documents` apropriadamente com o novo documento encontrado. Para testar tanto esta atividade e a seguinte,  voc√™ dever√° fazer uma das implementa√ß√µes dessa classe - a classe **HashIndex** - na atividade 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 2- atributos calculados da classe Index**: Por meio dos atributos existentes na classe `Index`, implemente os atributos calculados `document_count` e `vocabulary` da classe Index: \n",
    "- O atributo `document_count` retorna a quantidade de documentos existentes (inteiro); \n",
    "- `vocabulary` retorna uma lista com o vocabul√°rio completo indexado (lista de string). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 3 - Implementa√ß√£o da classe HashIndex:** O HashIndex dever√° fazer um √≠ndice em mem√≥ria.\n",
    "\n",
    "Como exemplo, caso tenhamos tr√™s documentos $d_1 = $\"A casa verde √© uma casa bonita\", $d_2 = $\"A casa bonita\" e $d_3 =$\"O pr√©dio verde\", caso n√£o haja remo√ß√£o de _stopwords_ nem acentos, o atributo `dic_index` dever√° possuir a seguinte estrutura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [(term_id:1 doc: 1 freq: 1), (term_id:1 doc: 2 freq: 1)],\n",
       " 'casa': [(term_id:2 doc: 1 freq: 2), (term_id:2 doc: 2 freq: 1)],\n",
       " 'verde': [(term_id:3 doc: 1 freq: 1), (term_id:3 doc: 3 freq: 1)],\n",
       " '√©': [(term_id:4 doc: 1 freq: 1)],\n",
       " 'uma': [(term_id:5 doc: 1 freq: 1)],\n",
       " 'bonita': [(term_id:6 doc: 1 freq: 1), (term_id:6 doc: 2 freq: 1)],\n",
       " 'o': [(term_id:7 doc: 3 freq: 1)],\n",
       " 'pr√©dio': [(term_id:8 doc: 3 freq: 1)]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from index.structure import *\n",
    "{\"a\": [TermOccurrence(1,1,1), TermOccurrence(2,1,1)],\n",
    " \"casa\": [TermOccurrence(1,2,2), TermOccurrence(2,2,1)],\n",
    " \"verde\": [TermOccurrence(1,3,1), TermOccurrence(3,3,1)],\n",
    " \"√©\": [TermOccurrence(1,4,1)],\n",
    " \"uma\": [TermOccurrence(1,5,1)],\n",
    " \"bonita\": [TermOccurrence(1,6,1),TermOccurrence(2,6,1)],\n",
    " \"o\": [TermOccurrence(3,7,1)],\n",
    " \"pr√©dio\": [TermOccurrence(3,8,1)]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por simplicidade deste √≠ndice, perceba que deixamos o `term_id` de forma repetida. Iremos deixar assim, por√©m poder√≠amos retirar essa redund√¢ncia para reduzir o consumo de mem√≥ria. que deixamos o `term_id` de forma repetida. Iremos deixar assim, por√©m poderiamos retirar essa redundancia para reduzir o consumo de mem√≥ria. Mesmo assim, lembre-se que, nesta pr√°tica, iremos implementar o √≠ndice em arquivo que ir√° ser melhor ainda na quest√£o de consumo de mem√≥ria ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O √≠ndice √© chamado da seguinte forma ‚Äî esse c√≥digo s√≥ ira funcionar depois que voc√™ terminar esta atividade :):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = HashIndex()\n",
    "#indexa√ß√£o do documento 1\n",
    "index.index(\"a\",1,1)\n",
    "index.index(\"casa\",1,2)\n",
    "index.index(\"verde\",1,1)\n",
    "index.index(\"√©\",1,1)\n",
    "index.index(\"uma\",1,1)\n",
    "#indexa√ß√£o do documento 2\n",
    "index.index(\"a\",2,1)\n",
    "index.index(\"casa\",2,1)\n",
    "index.index(\"bonita\",2,1)\n",
    "\n",
    "#indexa√ß√£o do documento 3\n",
    "index.index(\"o\",3,1)\n",
    "index.index(\"pr√©dio\",3,1)\n",
    "index.index(\"verde\",3,1)\n",
    "\n",
    "index.finish_indexing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que o m√©todo `index` e `finish_indexing` s√£o da classe abstrata, ou seja, funcionar√£o para qualquer estrutura de indice. A classe `Index` √© que ir√° manter o dicin√°rio com o vocabul√°rio do √≠ndice e suas ocorrencias ser√£o armazenadas de forma diferente, de acordo com a implementa√ß√£o das subclasses:\n",
    "- A classe `HashIndex`, ir√° armazenar o indice e suas ocorrencias em mem√≥ria principal \n",
    "- A classe `FileIndex` armazenar√° as ocorr√™ncias em arquivo, ambas subclasses de `Index`. \n",
    "\n",
    "O m√©todo `finish_indexing` √© um m√©todo que n√£o est√° implementado no `Index` e √© implementado (opcionalmente) nas suas subclasses caso haja necessidade de fazer algo no final da indexa√ß√£o. Em nosso caso, apenas a classe `FileIndex` ir√° precisar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, voc√™ dever√° implementar a classe HashIndex. Para isso, voc√™ dever√° completar os m√©todos `create_index_entry` e `add_index_occur` que s√£o bem simples. Esse m√©todos s√£o respons√°veis, respectivamente, por criar uma entrada no dicion√°rio `dic_index` e adicionar mais uma ocorrencia nele.  Tais m√©todos foram criados para deixarmos em responsabilidade das subclasses a manipula√ß√£o dessa nova entrada, pois, dependendo da estrutura do √≠ndice, ela ser√° diferente. Implemente de acordo com a descri√ß√£o abaixo e veja tamb√©m o m√©todo `index` da classe `Index` para entender melhor como esses m√©todos s√£o usados.\n",
    "- `create_index_entry`: cria uma nova entrada no √≠ndice utilizando, se necess√°rio, o id do termo passado como par√¢metro - esse id n√£o ser√° necess√°rio para a HashIndex. No caso dessa classe, a implementa√ß√£o deste m√©todo √© **super simples** - apenas substitua o None por uma lista vazia;\n",
    "- `add_index_occur`: Adiciona uma nova ocorrencia   neste √≠ndice. Voc√™ ter√° como entrada: o termo desta ocorrencia, o id do documento e frequencia do termo no documento. Voc√™ dever√° instanciar um objeto da classe `TermOccurrence` substituindo o `None` apropriadamente. \n",
    "\n",
    "\n",
    "Fa√ßa os testes abaixo para garantir que a atividade atual e as duas anteriores foram implementadas corretamente. Nos primeiros dois testes, voc√™ ainda n√£o ver√° a lista de ocorr√™ncias, pois o m√©todo para obt√™-la ser√° implementado a seguir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m index.index_structure_test StructureTest.test_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m index.index_structure_test StructureTest.test_document_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, implemente o m√©todo `get_occurrence_list`: Retornar√° a lista de ocorrencias de um determinado termo. Considerando o exemplo apresentado no inicio desta atividade, `index.get_occurrence_list('casa')` retornar√° a lista `[TermOccurrence(1,2,2), TermOccurrence(2,2,1)]`. Caso um termo n√£o exista, este m√©todo dever√° retornar uma lista vazia. Logo ap√≥s, execute o teste abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m index.index_structure_test StructureTest.test_get_occurrence_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemente o atributo calculado `document_count_with_term` que retorna a quantidade de documentos que possuem um determinado termo. Considerando o exemplo apresentado no inicio desta atividade, `index.document_count_with_term('casa')` retornar√° 2. Caso um termo n√£o exista, este m√©todo dever√° retornar zero. Logo ap√≥s, execute o teste abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m index.index_structure_test StructureTest.test_document_count_with_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 4 ‚Äî m√©todos de compara√ß√£o da classe TermOccurrence**: Eventualmente iremos precisar ordenar as ocorr√™ncias Por isso, temos que implementar os [comparadores de `__eq__` e `__lt__`](https://docs.python.org/3.7/reference/datamodel.html#object.__lt__) al√©m de usar o _decorator_ [total_ordering](https://docs.python.org/3.7/library/functools.html#functools.total_ordering) - [veja tamb√©m aqui](https://portingguide.readthedocs.io/en/latest/comparisons.html#rich-comparisons). O m√©todo `__eq__` retorna igual se um objeto √© considerado igual ao outro. Considere que uma ocorr√™ncia √© igual a outra se o id do termo dela e o id do documento forem iguais.\n",
    "\n",
    "O comparador `<` √© implementado pelo m√©todo `__lt__` que retorna verdadeiro se o objeto corrente `self` √© menor que o objeto passado como par√¢metro. A ocorr√™ncia dever√° ser ordenada primeiramente pelo seu `term_id` e, logo ap√≥s, pelo `doc_id`. Fa√ßa o exemplo abaixo para testar (n√£o esque√ßa de reiniciar o Kernel quando modificar o c√≥digo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index.structure import *\n",
    "t1 = TermOccurrence(1,1,2)\n",
    "t2 = TermOccurrence(3,1,2)\n",
    "t3 = TermOccurrence(1,2,2)\n",
    "t4 = TermOccurrence(2,2,2)\n",
    "t5 = TermOccurrence(2,2,2)\n",
    "\n",
    "\n",
    "print(f\"Resultado obtido: {t1 == t5} - esperado: False\")\n",
    "print(f\"Resultado obtido: {t4 == t5} - esperado: True\")\n",
    "print(f\"Resultado obtido: {t1 != t1} - esperado: False\")\n",
    "print(f\"Resultado obtido: {t1 is None} - esperado: False\")\n",
    "print(f\"Resultado obtido: {t1 < t2} - esperado: True\")\n",
    "print(f\"Resultado obtido: {t2 > t3} - esperado: False\")\n",
    "print(f\"Resultado obtido: {t3 < t4} - esperado: True\")\n",
    "print(f\"Resultado obtido: {t2 > t4} - esperado: False\")\n",
    "print(f\"Resultado obtido: {t2 > None} - esperado: False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa forma, voc√™ implementou todos os m√©todos para indexa√ß√£o usando mem√≥ria principal por meio da classe `HashIndex`. Abaixo, \"brinque\" com os m√©todos \"index\" e, logo ap√≥s, testar o resultado dos m√©todos implementados (tanto de retornar uma lista de ocorrencia quanto de verificar a quantidade de documentos com um determinado termo). Dentre os termos a serem indexados, indexe os sete √∫ltimos digitos do n√∫mero de matr√≠cula de cada integrante do grupo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constru√ß√£o de √≠ndice usando arquivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A constru√ß√£o de √≠ndice usando apenas mem√≥ria principal √© f√°cil de implementar e eficiente em termos de tempo de execu√ß√£o. Por√©m, quando precisamos de indexar milh√µes/bilh√µes de p√°ginas, √© muitas vezes invi√°vel armazenarmos tudo em mem√≥ria principal. \n",
    "\n",
    "Para resolver esse problema, uma solu√ß√£o √© mantermos o vocabul√°rio em mem√≥ria principal e as ocorr√™ncias em mem√≥ria secund√°ria. Assim, ter√≠amos o mesmo atributo `dic_index` na classe `Index`. Por√©m, cada entrada (termo) referenciar√° as ocorrencias em arquivo. Utilizando exemplo da `atividade 3`neste contexto, no final da indexa√ß√£o, o `dic_index` deve ficar da seguinte forma: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"a\": TermFilePosition(term_id=1,  term_file_start_pos=0, doc_count_with_term=2), \n",
    " \"casa\": TermFilePosition(2, 20, 2), \n",
    " \"verde\": TermFilePosition(3, 40, 2),\n",
    " \"√©\": TermFilePosition(4, 60, 1), \n",
    " \"uma\": TermFilePosition(5, 70, 1), \n",
    " \"bonita\": TermFilePosition(6, 80, 2), \n",
    " \"o\": TermFilePosition(7, 100, 1), \n",
    " \"pr√©dio\": TermFilePosition(8, 110, 1), \n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As ocorr√™ncias s√£o ordenadas por termo e, logo ap√≥s, por documento. Dessa forma, elas ficariam em um arquivo na seguinte ordem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[TermOccurrence(1,1,1), \n",
    " TermOccurrence(2,1,1), \n",
    " TermOccurrence(1,2,2), \n",
    " TermOccurrence(2,2,1),\n",
    " TermOccurrence(1,3,1), \n",
    " TermOccurrence(3,3,1),\n",
    " TermOccurrence(1,4,1),\n",
    " TermOccurrence(1,5,1),\n",
    " TermOccurrence(1,6,1),\n",
    " TermOccurrence(2,6,1),\n",
    " TermOccurrence(3,7,1),\n",
    " TermOccurrence(3,8,1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em que cada inst√¢ncia da classe `TermFilePosition` √© a especifica√ß√£o da posi√ß√£o inicial de um `term_id` em um arquivo al√©m de especificar tamb√©m a quantidade de ocorr√™ncias desse termo. Essa posi√ß√£o inicial e quantidade s√£o definidas nos atributos `term_file_start_pos` e `doc_count_with_term`, respetivamente. A posi√ß√£o inicial est√° em ‚Äòbytes‚Äô e, nesse exemplo, foi considerado que cada TermOcurrence possui 10 ‚Äòbytes‚Äô. Assim, por exemplo, o termo casa (term_id=2) inicia-se na posi√ß√£o 20 e possui duas ocorr√™ncias. Com isso, √© poss√≠vel obter todas as ocorr√™ncias de um determinado termo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para deixarmos a estrutura dessa forma, temos um dificultador: no arquivo, temos que ordenar as ocorrencias pelo termo, por√©m, indexamos por documento. Assim, se grav√°ssemos as ocorr√™ncias assim que indexarmos, as gravariamos agrupadas por documento (veja na atividade 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, temos que garantir uma ordena√ß√£o por termo do arquivo externo, lembrando que nem sempre √© poss√≠vel armazenar todo o arquivo em mem√≥ria principal. Para resolvermos isso, faremos o seguinte:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sempre, ao indexar, salvaremos o indice em uma lista (tempor√°ria) de ocorrencia de termos `lst_occurrences_tmp`\n",
    "- Usaremos o m√©todo `save_tmp_occurrences` para, assim que a lista estiver com um determinado tamanho, orden√°-la pelo termo e salvar de formar ordenada em um novo arquivo de indice com a todas as ocorrencias. Para que seja feito isso, voc√™ dever√° fazer uma ordena√ß√£o externa lendo em considera√ß√£o o √≠ndice em arquivo atual e a lista de ocorrencias tempor√°rias. Veja a seguir o passo a passo geral da indexa√ß√£o. As proximas atividades ir√£o te guiar para que seja implementado:\n",
    "    - (1) ordene a lista `lst_occurrences_tmp`. Lembre-se que voc√™ implementou os comparadores das inst√¢ncias TermOccurrence, assim, a ordena√ß√£o e descobrir o menor valor entre as ocorrencias √© uma opera√ß√£o simples;\n",
    "    - (2) criar um arquivo novo;\n",
    "    - (3) compare a primeira posi√ß√£o da lista com a primeira posi√ß√£o do arquivo de √≠ndice, sempre inserindo a ocorrencia considerada com o menor entre elas no novo arquivo. Lembrando novamente que os comparadores foram implementados e que voc√™ possui os m√©todos `next_from_list` e `next_from_file` - que ser√° implementado na atividade 5 para ajudar;\n",
    "    - (4) esse novo arquivo passar√° a ser o √≠ndice. Exclua o indice antigo e limpe a lista de ocorr√™ncias `lst_occurrences_tmp`.\n",
    "- O m√©todo `finish_indexing` √© o m√©todo que ser√° chamado ao finalizar a indexa√ß√£o. Neste contexto ele ser√° usado para organizar o `dic_index`. Lembrando que, neste contexto, `dic_index` mapeia uma palavra (string) a uma instancia de `TermFilePosition`, este m√©todo ir√° atualizar  os atributos `term_file_start_pos` e `doc_count_with_term` de cada instancia  de `TermFilePosition` para os valores corretos, considerando que termo ele se refere no arquivo do √≠ndice.\n",
    "\n",
    "Na primeira execu√ß√£o, n√£o haver√° arquivo e voc√™ adicionar√° a lista toda no arquivo de forma sequencial. Fazendo esse procedimento, voc√™ sempre ir√° garantir um arquivo ordenado da forma esperada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 5(a) ‚Äî escrita e leitura das ocorrencias em arquivo:** Iremos necessitarda leitura e escrita de uma inst√¢ncia de `TermOccurrence` que est√° persistida em arquivo. Assim deveremos implementar o m√©todo de escrita em arquivo nessa classe. Para economizar espa√ßo e por simplicidade, ser√° escrito num arquivo bin√°rio armazenando os tr√™s atributos inteiros. Cada inteiro ser√° armazenado em 4 ‚Äòbytes‚Äô ‚Äî ser√° o suficiente para a nossa indexa√ß√£o. Veja um exemplo abaixo de escrita, leitura e impress√£o do posicionamento no arquivo (esses m√©todos ser√£o √∫teis nessa atividade)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n",
      "n√∫mero: 100\n"
     ]
    }
   ],
   "source": [
    "x = 100\n",
    "with open(\"xuxu.idx\",\"wb\") as file:\n",
    "    print(file.tell())\n",
    "    file.write(x.to_bytes(4,byteorder=\"big\"))\n",
    "    print(file.tell())\n",
    "with open(\"xuxu.idx\",\"rb\") as file:\n",
    "    print(f\"n√∫mero: {int.from_bytes(file.read(4),byteorder='big')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa forma, implemente: \n",
    "\n",
    "- o m√©todo `write` da classe `TermOccurence` respons√°vel por gravar os atributos `doc_id`, `term_id` e `term_freq` do objeto corrente.\n",
    "- complete o m√©todo `next_from_file` da classe `FileIndex`. Este m√©todo j√° possui um arquivo aberto e voc√™ dever√° ler o pr√≥ximo objeto da classe `TermOccurence` que foi escrito neste arquivo pelo m√©todo `write` implementado acima. Caso n√£o haja mais ocorrencia, √© retornado `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m index.file_index_test FileIndexTest.test_next_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 5 (b) - leitura e obten√ß√£o do pr√≥ximo elemento da lista**: Conforme dito, iremos usar uma lista de ocorrencias em mem√≥ria principal para, logo ap√≥s, armazenar cada ocorr√™ncia, de forma ordenada em arquivo. Essa lista de ocorrencia √© o atributo `lst_occurrences_tmp`. Dessa forma, temos que implementar os m√©todos da classe `FileIndex`:\n",
    "\n",
    "- `create_index_entry`: instancia um elemento da classe `FilePosition` com o seu respectivo id do termo, passado como par√¢metro\n",
    "- `add_index_occur`: Cria e adiciona uma nova ocorr√™ncia na lista de ocorrencias tempor√°rias `lst_occurrences_tmp` e, caso senha passado o limite `FileIndex.TMP_OCCURRENCES_LIMIT` do n√∫mero m√°ximo de ocorrencias na lista, chamar o m√©todo `save_tmp_occurrence` (ainda ser√° implementado). \n",
    "- `next_from_list`: Retorna o primeiro elemento da lista, eliminando-o da lista. Caso n√£o exista, retorna `None`. Este m√©todo √© √∫til para obter o menor elemento da lista, quando a mesma estiver ordenada de forma crescente (o que ir√° ocorrer em `save_tmp_occurences`). \n",
    "\n",
    "Poder√≠amos implementar esses dois m√©todos de forma simples utilizando as fun√ß√µes `append` e `pop` da lista. Por√©m, a complexidade de tempo no pior caso no `append` √© O(N) em tempo e espa√ßo (quando o tamanho da lista exceder o tamanho anteriormente alocado) e o `pop` a complexidade de tempo √© O(N) para retirar o primeiro elemento da lista. Dessa forma, como iremos fazer uma lista com 1 milh√£o de ocorr√™cias que ir√£o ser modificados constantemente, essas opera√ß√µes seriam muito custoas. \n",
    "\n",
    "Uma das solu√ß√µes para contornar esse problema √© utilizamos uma lista fixa de  tamanho `TMP_OCCURRENCES_LIMIT` e vari√°veis auxiliares para indicar o in√≠cio e fim da lista. Dessa forma, nesta classe, possu√≠mos os atributos `idx_tmp_occur_first_element` e `idx_tmp_occur_last_element` para indicar a posi√ß√£o do primeiro e ultimo item v√°lido na lista. A lista ser√° inicializada no construtor com `TMP_OCCURRENCES_LIMIT` instancias `None`. A inicializa√ß√£o desses atributos j√° foi implementada no construtor. Implementamos o m√©todo `get_tmp_occur_size` para obter o tamanho dessa lista. Como alternativa a essa soluca√ß√£o, poderiamos usar uma [lista encadeada (deque)](https://docs.python.org/3/library/collections.html#collections.deque). Mas, nessa atividade, voc√™ n√£o poderia fazer com a lista encadeada apenas porque os testes automatizados n√£o funcionariam ;-). Complete a implementa√ß√£o dos m√©todos `add_index_occur` e o m√©todo `next_from_list` apropriadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m index.file_index_test FileIndexTest.test_next_from_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 6 - m√©todo save_tmp_occurrences:** Implemente o m√©todo `save_tmp_occurrences`. Esse m√©todo dever√° fazer a jun√ß√£o do √≠ndice atual e a lista `lst_occurrences_tmp` em novo arquivo de √≠ndice de forma ordenada, conforme explicado anteriormente no in√≠cio desta se√ß√£o. Neste m√©todo, voc√™ n√£o precisa preocupar com o atributo `dic_index`. Al√©m da lista, leve em considera√ß√£o os seguintes atributos/m√©todos:\n",
    "\n",
    "- `idx_file_counter`:  No c√≥digo, voc√™ ir√° criar sempre novos indices, excluindo o antigo. Este atributo ser√° √∫til para definirmos o nome do arquivo do √≠ndice. O novo arquivo do √≠ndice chamar√° `occur_index_X` em que $X$ √© o n√∫mero do mesmo. \n",
    "- `str_idx_file_name`: Atributo que armazena o arquivo √≠ndice atual. A primeira vez que executarmos `save_tmp_occurrences` n√£o haver√° arquivo criado e, assim `str_idx_file_name = None`\n",
    "- `next_from_file` e `next_from_list`: implementados na atividade anterior, para obter o pr√≥ximo item do arquivo ou da lista. Lembre-se que a lista deve estar ordenda antes de juntar a lista e o arquivo de indice atual em um novo arquivo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute o teste unit√°rio abaixo para verificar corretude deste c√≥digo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m index.file_index_test FileIndexTest.test_save_tmp_occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 7: m√©todo finish_indexing:** Para que o `dic_index` encontre as ocorrencias no arquivo, para cada termo, √© mapeado o `TermFilePosition` correspondente. Agora, com as ocorr√™ncias organizadas no arquivo por termo, voc√™ dever√° implementar o m√©todo `finish_indexing` para atualizar o atributo `dic_index` colocando, para cada instancia de `TermFilePosition` a posi√ß√£o inicial e quantidade de documentos de cada termo`. Logo ap√≥s, execute o teste unit√°rio abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m index.file_index_test FileIndexTest.test_finish_indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 8 - implementa√ß√£o em `FileIndex` dos m√©todos abstratos da classe Index:** Como voc√™s perceberam, `FileIndex` √© subclasse de `Index`. Assim,  precisamos implementar os m√©todos abstratos da classe `Index`:\n",
    "\n",
    "- `create_index_entry`: no `FileIndex` para criar uma nova entrada no √≠ndice, voc√™ dever√° retornar uma instancia de `TermFilePosition` para este novo `term_id`. Ao cri√°-lo, voc√™ n√£o precisa de definir a posi√ß√£o inicial do arquivo nem a quantidade de documentos. Conforme voc√™s implementaram nas atividades anteriores, isso √© feito apenas no momento de finaliza√ß√£o da indexa√ß√£o;\n",
    "- `get_occurrence_list` e `document_count_with_term`: Possuem as mesmas funcionalidades descritas na atividade 3, por√©m, agora voc√™ dever√° considerar a estrutura criada no `FileIndex`. Lembrem-se que esse m√©todo √© s√≥ chamado ap√≥s a finaliza√ß√£o da indexa√ß√£o, assim, considere que o √≠ndice j√° est√° pronto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 9 - Teste unit√°rio** Dessa vez, voc√™ dever√° alterar uma classe de teste unit√°rio para conseguir execut√°-la. \n",
    "\n",
    "Agora iremos testar os m√©todos get_occurrence_list e document_count_with_term. Lembre-se que j√° temos um teste unit√°rio para isso, por√©m ele testa a estrutura de um `HashIndex`. Neste caso, iremos apenas mudar a estrutura, mas os m√©todos ser√£o o mesmo, por isso, conseguiremos reaproveitar o teste feito anteriormente criando apenas uma nova classe de teste. \n",
    "\n",
    "Implementando este teste, voc√™ perceber√° como √© lindo usar orienta√ß√£o objetos ao seu favor ü•∞. No arquivo `index_structure_test.py` voc√™ possui a classe `FileStructureTest` que √© subclasse de nosso teste criado `StructureTest`.  Voc√™ dever√° implementar o m√©todo `setUp` na classe `FileStructureTest` que sobrep√µe o m√©todo de mesmo nome na classe `StructureTest`. O m√©todo `setUp` √© executado sempre antes do teste. Este m√©todo que voc√™ ir√° criar ir√° fazer exatamente a mesma coisa que o criado em `StructureTest` por√©m, voc√™ dever√° instanciar um `FileIndex` ao inv√©s de um `HashIndex`. Logo ap√≥s, execute os testes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m index.index_structure_test  FileStructureTest.test_document_count_with_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m index.index_structure_test  FileStructureTest.test_get_occurrence_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma similar, tamb√©m criamos um teste de desempenho. Verifique o desempenho da indexa√ß√£o em arquivo e em mem√≥ria ao indexar milh√µes de ocorr√™ncias de termos utilizando os testes abaixo. Note que, desta vez, estamos chamando os testes por comandos Python e n√£o pelo terminal e estamos fazendo testes de mem√≥ria. Dessa forma, voc√™ deve reiniciar o kernel sempre antes de executar cada um dos dois testes abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- √çndice completamente em mem√≥ria principal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from index.performance_test import PerformanceTest\n",
    "\n",
    "PerformanceTest.NUM_DOCS = 250\n",
    "PerformanceTest.NUM_TERM_PER_DOC = 1000\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(PerformanceTest)\n",
    "unittest.TextTestRunner(verbosity=2).run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- √çndice com ocorr√™ncias em mem√≥ria secund√°ria. Veja que, abaixo, que voc√™ pode ajustar o par√¢metro de n√∫mero de ocorr√™ncias em mem√≥ria. Ser√° muito √∫til para n√£o gastar tanto tempo ao indexar o conte√∫do da Wikip√©dia. **Reinicie o kernel antes de executar.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from index.performance_test import FilePerformanceTest,PerformanceTest\n",
    "from index.structure import FileIndex\n",
    "\n",
    "PerformanceTest.NUM_DOCS = 250\n",
    "PerformanceTest.NUM_TERM_PER_DOC = 1000\n",
    "FileIndex.TMP_OCCURRENCES_LIMIT = 100000\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(FilePerformanceTest)\n",
    "unittest.TextTestRunner(verbosity=2).run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logo ap√≥s executado este teste, voc√™ dever√° usar a biblioteca [JSON](https://docs.python.org/3/library/json.html) ou [Pickle](https://docs.python.org/3/library/pickle.html) para armazenar o vocabul√°rio. Com isso, crie um m√©todo de leitura do FileIndex e do HashIndex e de escrita. O m√©todo de leitura dever√° ser um m√©todo estatico que retorna um objeto da classe indice previamente criado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 10 - Grava√ß√£o do √≠ndice (completo) em mem√≥ria secund√°ria:** Use o [pickle](https://docs.python.org/3/library/pickle.html) e implemente o m√©todo write da classe `Index` que grava o √≠ndice em mem√≥ria secund√°ria e o m√©todo est√°tico `read`, que l√™ o √≠ndice em arquivo e o retorna. A seguir, execute os testes para leitura e escrita tanto usando o `FileIndex` quanto o `HashIndex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m index.index_structure_test StructureTest.test_read_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m index.index_structure_test FileStructureTest.test_read_write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexador de HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, voc√™ ir√° alterar o arquivo `indexer.py` para [preprocessar conte√∫do HTML](https://docs.google.com/presentation/d/1C22jQWIYobiqMx8SmP1y2lr1uSlvJSu3ayu5lXC5d8A/edit?usp=sharing) e depois index√°-lo. Com isso, voc√™ poder√° us√°-lo para indexa√ß√£o das p√°ginas HTML, como os da Wikip√©dia. A classe `Cleaner` ser√° respons√°vel pelo preprocessamento e a HTMLIndexer, para a indexa√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index.indexer import *\n",
    "#importamos o m√≥dulo structure\n",
    "#novamente para n√£o precisar de executar o c√≥digo do in√≠cio da tarefa\n",
    "from index.structure import *\n",
    "#Fazemos o download do m√≥dulo nlkt para a quest√£o 12\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 11 - Limpeza dos dados com a classe Cleaner:** A classe `Cleaner` √© respons√°vel por preprocessar o conte√∫do HTML para que ele esteja preparado para indexa√ß√£o. Essa classe tem alguns _flags_ para definir se algum tipo de processamento opcional ser√° feito (por exemplo, _stemming_ e remo√ß√£o de _stopwords_). Para isso, voc√™ dever√° implementar pequenos m√©todos para fazer a limpeza. Esses c√≥digos s√£o pequenos pois temos lindas APIs para nos ajudar üíï. Voc√™ ir√° fazer o processamento b√°sico e, se quiser, pode melhorar a implementa√ß√£o criando exce√ß√µes na remo√ß√£o de acentos e n√£o retirando mai√∫sculas e min√∫sculas de certas palavras e unindo palavras compostas, por exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada tarefa, h√° um m√©todo para ser criado a seguir os testes iniciais ser√£o feitos aqui no Jupyter. N√£o esque√ßa de reiniciar o kernel sempre que alterar algo no c√≥digo. Logo ap√≥s, haver√° um [teste de integra√ß√£o](https://en.wikipedia.org/wiki/Integration_testing) para avaliar a indexa√ß√£o como um todo.\n",
    "\n",
    "- **Transforma√ß√£o de HTML para texto:** Na limpeza dos dados, iremos remover tudo que n√£o ser√° indexado ‚Äî ou seja, o c√≥digo HTML. Para isso, iremos implementar o m√©todo `html_to_plain_text` que transformar√° o HTML em texto corrido. Voc√™ pode utilizar o [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) para isso e o m√©todo get_text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner_test = Cleaner(stop_words_file=\"stopwords.txt\",\n",
    "                        language=\"portuguese\",\n",
    "                        perform_stop_words_removal=True,\n",
    "                        perform_accents_removal=True,\n",
    "                        perform_stemming=True)\n",
    "cleaner_test.html_to_plain_text(\"&copy; oi! Meu nome √© <strong>Hasan</strong>\")\n",
    "#esperado: '¬© oi! Meu nome √© Hasan'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Verifica se √© stopword**: O m√©todo `is_stopword` retorna verdadeiro se uma palavra, passada como par√¢metro, √© stopword. Para isso, voc√™ ir√° usar o atributo `set_stop_words`. Este atributo foi inicializado com um conjunto de stopwords de um arquivo. Esse arquivo, para testes, tem poucas stopwords.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{cleaner_test.is_stop_word('jap√£o')}, esperado: False\")\n",
    "print(f\"{cleaner_test.is_stop_word('cama')}, esperado: False\")\n",
    "print(f\"{cleaner_test.is_stop_word('√©')}, esperado: True\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Stemming**: voc√™ dever√° implementar o m√©todo word_stem para ralizar o stemming. Voc√™ dever√° usar a [classe SnowballStemmer da API NLTK](https://www.nltk.org/howto/stem.html). Um objeto dessa classe j√° est√° instanciado no atributo `stemmer`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{cleaner_test.word_stem('verdade')}, esperado: verdad\")\n",
    "print(f\"{cleaner_test.word_stem('estudante')}, esperado: estud\")\n",
    "print(f\"{cleaner_test.word_stem('amado')}, esperado: amad\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Remo√ß√£o de acentos:** Iremos fazer de uma forma bem simples a remo√ß√£o de acentos: aplicando uma tabela de substitui√ß√£o de caracteres. Para isso, voc√™ dever√° criar uma [tabela de tradu√ß√£o](https://docs.python.org/3.3/library/stdtypes.html?highlight=maketrans#str.maketrans) no atributo `accents_translation_table` baseando-se nas vari√°veis `in_table` e `out_table` tamb√©m presentes no construtor (substitua o None)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{cleaner_test.remove_accents('can√ß√£o')}, esperado: cancao\")\n",
    "print(f\"{cleaner_test.remove_accents('el√©trico')}, esperado: eletrico\")\n",
    "print(f\"{cleaner_test.remove_accents('amado')}, esperado: amado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora voc√™ ir√° fazer o m√©todo `preprocess_word` e o `preprocess_text`:\n",
    "\n",
    "- o `preprocess_text` receber√° o texto \"limpo\" (j√° sem c√≥digo html), ir√° converter tudo para minuscula e remover acentos\n",
    "- o `preprocess_word` ir√° receber como parametro uma palavra e ir√° verificar se √© uma palavra v√°lida de ser indexada. Uma palavra v√°lida a ser indexada √© aquela que n√£o √© pontua√ß√£o e n√£o √© stopword (caso `perform_stop_words_removal = True`). Caso n√£o seja v√°lida, retornar√° None. Caso contr√°rio, ir√° retornar a palavra preprocessada. Para que seja feito o preprocessamento voc√™ dever√°: fazer o stemming (se `perform_stemming = True`) - neste exemplo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 13 ‚Äî Classe HTMLIndexer ‚Äî m√©todo text_word_count:** Voc√™ dever√° implementar o m√©todo `text_word_count`, a partir de um texto. Esse m√©todo retorna um dicion√°rio em que, para cada palavra no texto, ser√° apresentado sua frequ√™ncia. Considere que o texto j√° est√° limpo e √© necess√°rio fazer apenas o processamento das palavras.\n",
    "\n",
    "Para isso, voc√™ dever√°: dividir o texto em tokens (que, no nosso caso, s√£o as palavras e pontua√ß√µes); pr√©-processar cada palavra usando o `HTMLIndexer.cleaner`; e, se for uma palavra v√°lida, contabiliz√°-la. Para isso, ser√° necess√°rio [o m√©todo word_tokenize da API NLTK](https://kite.com/python/docs/nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = HashIndex()\n",
    "indexador_teste = HTMLIndexer(index)\n",
    "indexador_teste.text_word_count(\"Ol√°! Qual √© o dado dado que precisa?\")\n",
    "#esperado:\n",
    "#{'dad': 2, 'o': 1, 'ola': 1, 'precis': 1, 'qual': 1, 'que': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 14 ‚Äî m√©todo index_text:** Implemente o m√©todo `index_text` que dever√° (1) converter o HTML para texto simples usando `HTMLIndexer.cleaner`; (2) converter o texto em um dicion√°rio de ocorrencias de palavras com sua frequencia (metodo da atividade 13); (3) indexar cada palavra deste dicion√°rio; e (4) no final da execu√ß√£o, n√£o esque√ßa de executar o m√©todo `finish_indexing` do √≠ndice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index = HashIndex()\n",
    "indexador_teste = HTMLIndexer(index)\n",
    "#o HTML est√° mal formado de prop√≥sito ;)\n",
    "indexador_teste.index_text(10,\"<strong>Ol&aacute;! </str> Quais s√£o os dados que precisar√°?\")\n",
    "\n",
    "indexador_teste.index.dic_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esperado:\n",
    "<pre>\n",
    "{'dad': [(term_id:4 doc: 10 freq: 1)],\n",
    " 'ola': [(term_id:0 doc: 10 freq: 1)],\n",
    " 'os': [(term_id:3 doc: 10 freq: 1)],\n",
    " 'precis': [(term_id:6 doc: 10 freq: 1)],\n",
    "'qua': [(term_id:1 doc: 10 freq: 1)],\n",
    " 'que': [(term_id:5 doc: 10 freq: 1)],\n",
    " 'sao': [(term_id:2 doc: 10 freq: 1)]}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 15: Indexa√ß√£o de um diret√≥rio com subdiret√≥rios** Voc√™ dever√° implementar o m√©todo `index_text_dir` que, dado um diret√≥rio, navega em todos os seus subdiret√≥rios e indexa todos os arquivos HTMLs. Considere que os arquivos sejam sempre nomeados pelo seu ID. Veja o exemplo em `doc_test`. Logo ap√≥s, execute o teste unit√°rio para ver a corretude do seu indexador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m index.indexer_test IndexerTest.test_indexer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 16 indexa√ß√£o dos artigos da Wikipedia:** Voc√™ dever√° indexar todos os artigos da Wikip√©dia que est√£o [neste reposit√≥rio](https://github.com/daniel-hasan/ri-tp-wiki-data/archive/refs/heads/master.zip) e logo ap√≥s, salve esse √≠ndice. Voc√™ usar√° ele para a pr√≥xima etapa do projeto, o processamento de consultas. \n",
    "\n",
    "Como s√£o dezenas de milhares de artigos, √© uma tarefa que consome muita mem√≥ria e **ir√° demorar horas**. Dessa forma, use o arquivo python `wikipedia_index.py` e execute esse arquivo no terminal. Salve esse indice como `wiki.idx`. Logo ap√≥s, execute o teste abaixo que ir√° ler este √≠ndice e verificar se os documentos foram salvos.\n",
    "\n",
    "Nesse indice, para passar nos testes, use a configura√ß√£o do `Cleaner` definida no `wikipedia_index.py`. Logo ap√≥s, voc√™ pode criar outros √≠ndices. Inclusive, para a proxima etapa do projeto, aconselho que voc√™ teste diversos preprocessamentos, inclusive, voc√™ deve tamb√©m achar um arquivo de stopwords com mais termos aos que feito neste teste. \n",
    "\n",
    "Voc√™ pode escolher entre o HashIndex ou FileIndex para indexar, lembrando que o HashIndex consume muito mais mem√≥ria principal.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m index.indexer_test IndexerTest.test_wiki_idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
